{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 09:04:17.409363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-08 09:04:17.409394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import h5py as h5\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data form files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File('./train_catvnoncat.h5', 'r') as f:\n",
    "    train_set_x = list(f.keys())[1]\n",
    "    train_set_y = list(f.keys())[2]\n",
    "    \n",
    "    cat_data = list(f[train_set_y])\n",
    "    image_data = list(f[train_set_x])\n",
    "\n",
    "with h5.File('./test_catvnoncat.h5', 'r') as f:\n",
    "    test_set_x = list(f.keys())[1]\n",
    "    test_set_y = list(f.keys())[2]\n",
    "    \n",
    "    cat_data_test = list(f[test_set_y])\n",
    "    image_data_test = list(f[test_set_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Images Function\n",
    "\n",
    "We use this function to convert the images to gray_scale and return them as a single vector (using reshape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    gray_images = []\n",
    "    for image in images:\n",
    "        gray_image = []\n",
    "        for line in image:\n",
    "            new_line = []\n",
    "            for pixel in line:\n",
    "                gray_value = (0.2126 * pixel[0] + 0.7152 * pixel[1] + 0.0722 * pixel[2]) / 255\n",
    "                new_line.append(gray_value)\n",
    "            gray_image.append(new_line)\n",
    "        gray_images.append(gray_image)\n",
    "    \n",
    "    gray_images = np.array(gray_images)\n",
    "    n_samples = len(gray_images)\n",
    "    gray_images = gray_images.reshape((n_samples, -1))\n",
    "    return gray_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalized_images = normalize_images(image_data)\n",
    "\n",
    "perceptron = Perceptron(random_state=1)\n",
    "perceptron.fit(normalized_images, cat_data)\n",
    "\n",
    "normalized_test_images = normalize_images(image_data_test)\n",
    "y_pred = perceptron.predict(normalized_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing Perceptron Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  7]\n",
      " [10 23]]\n",
      "[[0.58823529 0.41176471]\n",
      " [0.3030303  0.6969697 ]]\n",
      "Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(cat_data_test, y_pred))\n",
    "print(confusion_matrix(cat_data_test, y_pred,normalize='true'))\n",
    "print('Accuracy: %.2f' % accuracy_score(cat_data_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 64), max_iter=300, random_state=8)\n",
    "mlp.fit(normalized_images, cat_data)\n",
    "mlp_predict = mlp.predict(normalized_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing MLPClassifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12]\n",
      " [ 2 31]]\n",
      "[[0.29411765 0.70588235]\n",
      " [0.06060606 0.93939394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.29      0.42        17\n",
      "           1       0.72      0.94      0.82        33\n",
      "\n",
      "    accuracy                           0.72        50\n",
      "   macro avg       0.72      0.62      0.62        50\n",
      "weighted avg       0.72      0.72      0.68        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(cat_data_test, mlp_predict))\n",
    "print(confusion_matrix(cat_data_test, mlp_predict,normalize='true'))\n",
    "print(classification_report(cat_data_test, mlp_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images shape: (209, 4096, 1)\n",
      "209 train samples\n",
      "50 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "train_images = cat_data\n",
    "train_labels = image_data\n",
    "test_images = cat_data_test\n",
    "test_labels = image_data_test\n",
    "\n",
    "train_images = normalize_images(image_data)\n",
    "test_images = normalize_images(image_data_test)\n",
    "\n",
    "train_images = np.expand_dims(train_images,-1)\n",
    "test_images = np.expand_dims(test_images,-1)\n",
    "\n",
    "print(\"train images shape:\", train_images.shape)\n",
    "print(train_images.shape[0], \"train samples\")\n",
    "print(test_images.shape[0], \"test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 09:04:40.968215: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-08 09:04:40.968277: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-08 09:04:40.968317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ibm4381): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "model_cnn = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
